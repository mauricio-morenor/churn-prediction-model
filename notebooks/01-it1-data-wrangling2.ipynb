{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "This notebook consists of the data consolidation and cleaning of the model. \n",
    "It includes a series of joins between the sellers considered for the first iteration and different variables grouped by the sellerID from CSVs\n",
    "\n",
    "**DF Structure**\n",
    "\n",
    "|  Name |Comments   |\n",
    "|---|---|\n",
    "| DFsellers1 |original sellers DF |\n",
    "| DFsellers2 | Include the threshold for the target variable (jun-2021)   |\n",
    "| DFsellers3| Include the orders information and dropped the sellers without orders   |\n",
    "| DFsellers4| Include the target variable   |\n",
    "| DFsellers5| Include referrals information   |\n",
    "| DFsellers6| Include products and categories information   |\n",
    "| DFsellers7| Include financial information of credits and vouchers   |\n",
    "\n",
    "DFsellers7 ended up with 263,265 and 32 columns (3 need to be dropped based). The columns can be labeled as transactional, operational and behavioural information.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sellers:\n",
    "- The DF had 1,723,856, but I established a treshold of sellers with creation date >= june 2021. Prior to that period there was a national strike that affected the conditions, and also, since it is a early stage company with many iterations in different areas changed the sellers' experience.\n",
    "- Additional sellers were dropped, for example, the ones banned from the business model and others labeld as ex-pioneer, which had a very different earnings schema and would add noice to the model\n",
    "- Additionally, non relevan columns such as business model or referred_by_id were droped\n",
    "- The last seller DF has 1,598,970 sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers1 = pd.read_csv(\"../Data/seller.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>referred_by_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>banned_elenas</th>\n",
       "      <th>ex_pioneer</th>\n",
       "      <th>business_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11391541</td>\n",
       "      <td>2022-09-23 00:10:33.003499+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11419818</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>DEFAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11534279</td>\n",
       "      <td>2022-11-21 00:36:52.063471+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11562762</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>DEFAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11543049</td>\n",
       "      <td>2022-11-25 13:52:46.429364+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11571595</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>DEFAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11554558</td>\n",
       "      <td>2022-12-01 06:30:08.778874+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11583127</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>DEFAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11567548</td>\n",
       "      <td>2022-12-07 15:24:24.01911+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11596129</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>DEFAULT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                     created_at  referred_by_id   user_id  \\\n",
       "0  11391541  2022-09-23 00:10:33.003499+02             NaN  11419818   \n",
       "1  11534279  2022-11-21 00:36:52.063471+01             NaN  11562762   \n",
       "2  11543049  2022-11-25 13:52:46.429364+01             NaN  11571595   \n",
       "3  11554558  2022-12-01 06:30:08.778874+01             NaN  11583127   \n",
       "4  11567548   2022-12-07 15:24:24.01911+01             NaN  11596129   \n",
       "\n",
       "   banned_elenas  ex_pioneer business_model  \n",
       "0          False       False        DEFAULT  \n",
       "1          False       False        DEFAULT  \n",
       "2          False       False        DEFAULT  \n",
       "3          False       False        DEFAULT  \n",
       "4          False       False        DEFAULT  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsellers1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally, there are 1.723.856 sellers\n",
    "dfsellers1.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation date & threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers1['created_at'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the 'created_at' column from a string to a datetime object with timezone information.\n",
    "dfsellers1['created_at'] = pd.to_datetime(dfsellers1['created_at'], utc=True)\n",
    "#convert the datetime objects to strings in the desired day format ('YYYY-MM-DD').\n",
    "dfsellers1['created_at'] = dfsellers1['created_at'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#Convert it back to datetime \n",
    "dfsellers1['created_at'] = pd.to_datetime(dfsellers1['created_at'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers1.head(5)\n",
    "dfsellers1.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfsellers 1: 1.723.856 sellers, created as string, 0 referred by id\n",
    "dfsellers2: copy of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_date = pd.to_datetime('2021-06-01')\n",
    "dfsellers2 = dfsellers1[dfsellers1['created_at'] >= threshold_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Banned review:\n",
    "dfsellers2[\"banned_elenas\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfsellers2 = dfsellers2[dfsellers2[\"banned_elenas\"] != True].reset_index(drop=True)\n",
    "#Sanity check\n",
    "dfsellers2.head()\n",
    "\n",
    "dfsellers2.drop(\"banned_elenas\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the banned sellers\n",
    "dfsellers2[dfsellers2[\"banned_elenas\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referrals elimination\n",
    "dfsellers2.drop(\"referred_by_id\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business model review:\n",
    "dfsellers2[\"business_model\"].value_counts()\n",
    "print(\"All the sellers have the same business model, the column will be eliminated\")\n",
    "dfsellers2.drop(\"business_model\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex pioneer review:\n",
    "dfsellers2[\"ex_pioneer\"].value_counts()\n",
    "f\"All the values of the ex_pioneer are the same. The column will be dropped\"\n",
    "\n",
    "dfsellers2.drop(\"ex_pioneer\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_rev(df):\n",
    "     \"\"\"\n",
    "    Calculates and displays information about missing values in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - percentage_nan (pandas.Series): The percentage of missing values for each column.\n",
    "    - missing_values_distribution (pandas.Series): The distribution of missing values for each column.\n",
    "    \"\"\"\n",
    "    # NaN values\n",
    "    total_nan = df.isna().sum().sum()\n",
    "    print(f\"{df} has {total_nan} NaN values\")\n",
    "\n",
    "    percentage_nan = df.isna().sum() / df.shape[0] * 100.0\n",
    "    print(\"The percentage of missing values for each column is:\")\n",
    "    print(percentage_nan)\n",
    "\n",
    "    missing_values_distribution = df.isna().sum()\n",
    "    print(\"Missing values distribution:\")\n",
    "    print(missing_values_distribution)\n",
    "\n",
    "    return  percentage_nan, missing_values_distribution\n",
    "\n",
    "print(nan_rev(dfsellers2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_vis(df):\n",
    "     \"\"\"\n",
    "    Visualizes missing values in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - str: A message indicating if there are any missing values or not.\n",
    "    - If there are missing values, returns a bar graph with the missing values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Visualize missing values\n",
    "    if df.isna().sum().sum() == 0:\n",
    "        return \"There are no missing values\"\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Missing Values\")\n",
    "        ax = sns.barplot(x=df.columns, y=df.isna().sum())\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "        plt.xlabel(\"Columns\")\n",
    "        plt.ylabel(\"Missing Values Count\")\n",
    "        plt.show()\n",
    "\n",
    "print(nan_vis(dfsellers2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers2.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename id to seller_id\n",
    "dfsellers2.rename(columns={'id': 'seller_id'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF Orders\n",
    "\n",
    "- I droped the sellers that have no placed orders, since they are not relevant for the business question. The number of sellers for the analysis is 279059 sellers\n",
    "- The added columns are aggregates of different metric for each seller. Depending of the variable relevance during the modeling stage, some variables could be desaggregated.\n",
    "- There are 67.5K NaN values of average effective delivery days. These come from sellers without effective orders, but the will be treated later.\n",
    "- Those sellers also had NaN values for columns such as total earnings or average earnings. Those missing values were replaced by 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforders1 = pd.read_csv(\"total_orders_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforders1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_info(df):\n",
    "    \"\"\"\n",
    "    Provides basic information about a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - list: A tuple containing lists of categorical columns and numerical columns, respectively.\n",
    "    \"\"\"\n",
    "    print(f\"The shape of the df is {df.shape}\")\n",
    "    print(f\"Number of datapoints: {df.count()}\")\n",
    "    print(\"\")\n",
    "    print(\"Data types:\")\n",
    "    print(df.dtypes)\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "    num_cols = df.select_dtypes(exclude=[\"object\"]).columns.to_list()\n",
    "    return cat_cols, num_cols\n",
    "\n",
    "\n",
    "print(basic_info(dforders1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforders1.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rev(dforders1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforders1[dforders1.isna().any(axis=1)]\n",
    "\n",
    "# They don't have effective orders\n",
    "def replace_nan_with_zero(df, columns):\n",
    "    \"\"\"\n",
    "    Replaces the NaN values with 0\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame.\n",
    "    - List columns of the DataFrame that will be removed.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): The input DataFrame with the updated values\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    df[columns] = df[columns].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dforders2 = replace_nan_with_zero(dforders1,[\"total_effective_earnings\", \"avg_effective_earnings\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforders2.count()\n",
    "#dfsellers2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfseller3: Left join between sellers (dfseller2) and orders dforders2\n",
    "dfsellers3 = pd.merge(dfsellers2, dforders2, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review if there are 0 in the total orders\n",
    "dfsellers3[dfsellers3[\"total_orders\"] == 0].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop sellers without any order\n",
    "dfsellers3.drop(dfsellers3[dfsellers3[\"total_orders\"].isna()].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF target variable 1st iteration\n",
    "\n",
    "- It is defined as a binary column for the effective orders (orders with state as completed, distribution, created, dispatched, in process, initial, ordered) and order created at >= 2023-03-30\n",
    "\n",
    "- The name of the variable is called: order_last_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftarget_it1 = pd.read_csv(\"target_var_first_iteration.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info(dftarget_it1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftarget_it1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the num_orders to a binary number\n",
    "dftarget_it1[\"num_orders\"] = dftarget_it1[\"num_orders\"].map(lambda x: 1 if x >= 1 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the num_orders to order_last_month\n",
    "dftarget_it1.rename(columns={\"num_orders\": \"order_last_month\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join sellers3 with target variable, and name it dfseller4\n",
    "dfsellers4 = pd.merge(dfsellers3, dftarget_it1, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers4.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referrals review\n",
    "\n",
    "- 2 relevant columns, is_referred, that will be binary and referred_by_seller_id that will change to a binary column named has_referred\n",
    "- After multiple analyses, the is_reffered column does not contain matching information for the sellers. The column will be dropped later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreferrals = pd.read_excel(\"referrals.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreferrals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreferrals.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referred sellers\n",
    "dfreferrals3 = dfreferrals.drop([\"referred_by_seller_id\"], axis=1)\n",
    "#Sanity check\n",
    "dfreferrals3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the 2 tables\n",
    "dfreferrals2 = pd.merge(dfreferrals, dfsellers2, left_on=\"referred_by_seller_id\", right_on=\"seller_id\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreferrals2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "#dfreferrals2.head(5)\n",
    "dfreferrals2.drop([\"seller_id_x\", \"seller_id_y\", \"is_referred\", \"created_at\", \"user_id\"], axis=1, inplace=True)\n",
    "#Sanity check\n",
    "dfreferrals2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary column of has_referred\n",
    "dfreferrals2[\"has_referred\"] = dfreferrals2[\"referred_by_seller_id\"].map(lambda x: 1 if x >= 1 else 0)\n",
    "\n",
    "#Rename\n",
    "dfreferrals2.rename(columns={\"referred_by_seller_id\": \"seller_id\"}, inplace=True)\n",
    "\n",
    "#Sanity check\n",
    "dfreferrals2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join between sellers and referred sellers (dfreferrals3)\n",
    "dfsellers5 = pd.merge(dfsellers4, dfreferrals3, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation that apparently there are no referrals:\n",
    "\n",
    "- Multiple analyses were performed, and there are no matches. Apparently the selected types of both tables are different, since the created at values are quite different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dfsellers4.seller_id).intersection(set(dfreferrals3.seller_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers4.seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreferrals3.seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One value validation\n",
    "dfsellers5[dfsellers5[\"seller_id\"] == 10030090].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation of all the rows\n",
    "# 0. Create a new validation df\n",
    "df_referral_val = dfsellers5[[\"seller_id\"]].copy()\n",
    "\n",
    "# 1. Create a list of each seller_id of dfreferrals3\n",
    "referral_validation = dfreferrals3[\"seller_id\"].tolist()\n",
    "\n",
    "# 2. Iterate through each element of dfsellers5, returning a True or False\n",
    "df_referral_val[\"is_duplicated\"] = dfsellers5[\"seller_id\"].apply(lambda x: True if x in referral_validation else False)\n",
    "\n",
    "# Count the values\n",
    "value_counts = df_referral_val[\"is_duplicated\"].value_counts()\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers5[\"is_referred\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join between sellers and sellers that have referred\n",
    "dfsellers5 = pd.merge(dfsellers5,dfreferrals2, on=\"seller_id\", how=\"left\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nan_with_zero(dfsellers5, [\"is_referred\", \"has_referred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers5[\"has_referred\"].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products\n",
    "\n",
    "- Include information on how the seller interacted with the different products and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproducts = pd.read_csv(\"total_cart_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info(dfproducts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join with the sellers Table\n",
    "dfsellers6 = pd.merge(dfsellers5, dfproducts, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers6.head(5)\n",
    "\n",
    "nan_vis(dfsellers6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproducts2 = pd.read_csv(\"products_shared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info(dfproducts2)\n",
    "\n",
    "dfproducts2.rename(columns={'id': 'seller_id'}, inplace=True)\n",
    "\n",
    "dfproducts2.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge products shared with sellers\n",
    "dfsellers6 = pd.merge(dfsellers6, dfproducts2, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactional information: credits & vouchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftransactional = pd.read_csv(\"seller_credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info(dftransactional)\n",
    "nan_vis(dftransactional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nan_with_zero(dftransactional,[\"avg_credit_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers7 = pd.merge(dfsellers6, dftransactional, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**vouchers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftransactional2 = pd.read_csv(\"seller_vouchers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info(dftransactional2)\n",
    "nan_vis(dftransactional2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join sellers7 with the vouchers information\n",
    "dfsellers7 = pd.merge(dfsellers7, dftransactional2, on=\"seller_id\", how=\"left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*checkpoint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint\n",
    "dfsellers7.to_csv('elenas-it1-preprocessed2.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers7 = pd.read_csv('elenas-it1-preprocessed2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data exploration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_vis(df, row, col, colorp):\n",
    "    # Initialization with the rows and columns for the subplot\n",
    "    fig = make_subplots(rows=row, cols=col)\n",
    "    \n",
    "    # List of the numerical columns\n",
    "    numeric_columns = df.select_dtypes(exclude=[\"object\"]).columns.to_list()\n",
    "    \n",
    "    # Loop, iterating on each column\n",
    "    for i, column in enumerate(numeric_columns):\n",
    "        # Number of rows based on index\n",
    "        row_num = (i // col) + 1\n",
    "        # Number of columns based on index, + 1 to start on the first position and have an integer\n",
    "        col_num = (i % col) + 1\n",
    "        \n",
    "        # Histogram of the variables\n",
    "        hist = px.histogram(df, x=column, color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "        \n",
    "        fig.add_trace(hist.data[0], row=row_num, col=col_num)\n",
    "        fig.update_xaxes(title_text=column, row=row_num, col=col_num)\n",
    "        fig.update_yaxes(title_text=\"Count\", row=row_num, col=col_num)\n",
    "    \n",
    "    fig.update_layout(height=400*row, width=400*col)\n",
    "    fig.show()\n",
    "\n",
    "num_vis(dfsellers7.round(1), 6, 6, \"RdPu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers7.describe().transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operational metrics\n",
    "def boxplot_vis(df, col1=0, col2=0, col3=0, col4=0, col5=0, col6=0):\n",
    "    # Create subplot with 2 rows and 3 columns\n",
    "    fig = make_subplots(rows=2, cols=3)\n",
    "\n",
    "    # Visualization for each value\n",
    "    if col1 != 0:\n",
    "        fig.add_trace(px.box(data_frame=df.round(0), y=col1).data[0], row=1, col=1)\n",
    "        fig.update_xaxes(title_text=col1, row=1, col=1)\n",
    "        fig.update_yaxes(title_text=input(\"write the y axis for the plot 1: \"), row=1, col=1)\n",
    "    if col2 != 0:\n",
    "        fig.add_trace(px.box(data_frame=df.round(0), y=col2).data[0], row=1, col=2)\n",
    "        fig.update_xaxes(title_text=col2, row=1, col=2)\n",
    "        fig.update_yaxes(title_text=input(\"write the y axis for the plot 2: \"), row=1, col=2)\n",
    "    if col3 != 0:\n",
    "        fig.add_trace(px.box(data_frame=df.round(0), y=col3).data[0], row=1, col=3)\n",
    "        fig.update_xaxes(title_text=col3, row=1, col=3)\n",
    "        fig.update_yaxes(title_text=input(\"write the y axis for the plot 3: \"), row=1, col=3)\n",
    "    if col4 != 0:\n",
    "        fig.add_trace(px.box(data_frame=df.round(0), y=col4).data[0], row=2, col=1)\n",
    "        fig.update_xaxes(title_text=col4, row=2, col=1)\n",
    "        fig.update_yaxes(title_text=input(\"write the y axis for the plot 4: \"), row=2, col=1)\n",
    "    if col5 != 0:\n",
    "        fig.add_trace(px.box(data_frame=df.round(0), y=col5).data[0], row=2, col=2)\n",
    "        fig.update_xaxes(title_text=col5, row=2, col=2)\n",
    "        fig.update_yaxes(title_text=input(\"write the y axis for the plot 5: \"), row=2, col=2)\n",
    "    if col6 != 0:\n",
    "        fig.add_trace(px.box(data_frame=df.round(0), y=col6).data[0], row=2, col=3)\n",
    "        fig.update_xaxes(title_text=col6, row=2, col=3)\n",
    "        fig.update_yaxes(title_text=input(\"write the y axis for the plot 6: \"), row=2, col=3)\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Average effective delivery days review:\n",
    "- The DF has over 60K missing average effective delivery days, these numbers are from sellers that don't have an effective order. So the order status is either cancelled, returned, RTO or lost.\n",
    "\n",
    "- The data of the avg_effective_delivery_days is skewed to the left, with a mean of 5.5 days and a median of 5 days. Since both results are of effective orders, I will use a higher value to fill the NaN, assuming that due to the order state, the experience was worse. \n",
    "\n",
    "- The NaNs were filled with 6, which is the Q3 of the values\n",
    "\n",
    "- Additionally, there are negative values, they will be updated with the mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_vis(dfsellers7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg delivery days top occurrences\n",
    "top_del_days = dfsellers7[\"avg_effective_delivery_days\"].round(0).value_counts().sort_values(ascending=False).iloc[:10]\n",
    "\n",
    "fig = px.bar(top_del_days, x='avg_effective_delivery_days')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_del_days = dfsellers7[\"avg_effective_delivery_days\"].round(0).value_counts().sort_values(ascending=False).iloc[:10]\n",
    "top_del_days = top_del_days.reset_index()  # Reset the index to make 'index' as a column\n",
    "\n",
    "fig = px.bar(top_del_days,\n",
    "              x='index',\n",
    "              y='avg_effective_delivery_days',\n",
    "              title=\"First 10 days delivery distribution\")\n",
    "fig.update_layout(xaxis_title=\"Average Delivery Days\", yaxis_title=\"Number of orders\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_delivery_days = dfsellers7[\"avg_effective_delivery_days\"].round(0)\n",
    "\n",
    "avg_delivery_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Delivery days value distribution\n",
    "\n",
    "\n",
    "\n",
    "fig = px.histogram(avg_delivery_days,\n",
    "                   x=\"avg_effective_delivery_days\",\n",
    "                   title=\"Avg effective delivery days distribution\",\n",
    "                   nbins=20)\n",
    "\n",
    "# Calculate the mean\n",
    "mean_delivery_days = np.mean(avg_delivery_days)\n",
    "\n",
    "# Add mean line to the plot\n",
    "fig.add_vline(x=mean_delivery_days, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"Mean: {mean_delivery_days:.2f}\")\n",
    "fig.update_layout(annotations=[dict(x=mean_delivery_days, y=1, text=f\"Mean: {mean_delivery_days:.2f}\",\n",
    "                                    showarrow=True, arrowhead=1, ax=20, ay=-20)])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Delivery days boxplot\n",
    "\n",
    "_ = dfsellers7[\"avg_effective_delivery_days\"].round(0)\n",
    "\n",
    "fig = px.box(_,\n",
    "                   x=\"avg_effective_delivery_days\",\n",
    "                   title=\"Avg effective delivery days distribution\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The avg delivery days will be changed to 6 for the nan values\n",
    "\n",
    "dfsellers7[\"avg_effective_delivery_days\"] = dfsellers7[\"avg_effective_delivery_days\"].fillna(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers7.T.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check:\n",
    "nan_vis(dfsellers7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative values - replaced with the mean\n",
    "dfsellers7[\"avg_effective_delivery_days\"] = dfsellers7[\"avg_effective_delivery_days\"].map(lambda x: 5.45 if x < 1 else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Delivery days boxplot\n",
    "\n",
    "_ = dfsellers7[\"avg_effective_delivery_days\"].round(0)\n",
    "\n",
    "fig = px.box(_,\n",
    "                   x=\"avg_effective_delivery_days\",\n",
    "                   title=\"Avg effective delivery days updated distribution\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop repeated column:\n",
    "dfsellers7.drop(\"number_of_vouchers_y\", axis=1, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint\n",
    "dfsellers7.to_csv('elenas-it1-preprocessed3.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsellers8 = pd.read_csv('elenas-it1-preprocessed2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
